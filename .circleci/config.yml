version: 2.1

nodeimg: &nodeimg
  docker:
    - image: circleci/node:13.8.0
  working_directory: ~/project

awscli: &awscli
  docker:
    - image: amazon/aws-cli
  working_directory: ~/project

ansibleimg: &ansibleimg
  docker:
    - image: python:3.7-alpine3.11
  working_directory: ~/project

commands:
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      # Add parameter here   
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
            pwd
            cat ~/my_env
            export $(grep BACKEND_STACK ~/my_env)
            export $(grep FRONTEND_STACK ~/my_env)
            echo $FRONTEND_STACK
            echo $BACKEND_STACK
            OUTPUT_KEY=WebsiteBucketName
            export BUCKET_NAME=$(aws cloudformation describe-stacks --stack-name $FRONTEND_STACK --query "Stacks[*].Outputs[?OutputKey=='$OUTPUT_KEY'].OutputValue" --output text)
            echo Bucket Name Is $BUCKET_NAME
            aws s3 rm s3://$BUCKET_NAME --recursive
            aws cloudformation delete-stack --stack-name $BACKEND_STACK
            aws cloudformation delete-stack --stack-name $FRONTEND_STACK

  update_ansible_image:
    description: install dependencies in python:3.7-alpine3.11 image
    steps:
      - run:
          name: Install dependencies
          command: |
            apk update
            apk add ansible curl
            pip3 install --upgrade pip
            pip3 install awscli
            aws sts get-caller-identity
            pwd
            cd .circleci/ansible
            cat inventory.txt
  
  install_aws_cli:
    description: Install AWS Cli
    steps:
      - run:
          name: Install
          command: |
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install

jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build

  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          command: |
             # Your code here
             cd backend
             npm install
             npm run build
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build

  test-frontend:
    <<: *nodeimg
    steps:
      - checkout
      - restore_cache:
          keys: [frontend]
      - run:
          name: Test Frontend
          command: |
            cd frontend
            npm install
            npm run test

  test-backend:
    <<: *nodeimg
    steps:
      - checkout
      - restore_cache:
          keys: [backend]
      - run:
          name: Test backend
          command: |
            cd backend
            npm install
            npm run test

  scan-frontend:
    <<: *nodeimg
    steps:
      - checkout
      - restore_cache:
          keys: [frontend]
      -  run:
          name: Scan Frontend
          command: |
            cd frontend
            npm install
            npm audit fix --audit-level=critical --force

  scan-backend:
    <<: *nodeimg
    steps:
      - checkout
      - restore_cache:
          keys: [backend]
      -  run:
          name: Scan Backend
          command: |
            cd backend
            npm audit fix --audit-level=critical --force

  deploy-infrastructure:
    <<: *awscli
    steps:
      - checkout
      - run:
           name: Install packages
           command: |
             yum install tar gzip -y
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            export ProjectName=udapeople
            echo BACKEND_STACK=udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7} >> ~/my_env
            export $(grep BACKEND_STACK ~/my_env)
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --stack-name $BACKEND_STACK \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"  \
              --tags project=udapeople \
      - run:
          name: Ensure front-end infrastructure exist
          command: |
            echo $ProjectName
            echo FRONTEND_STACK=udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7} >> ~/my_env
            export $(grep FRONTEND_STACK ~/my_env) 
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --stack-name $FRONTEND_STACK \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"  \
              --tags project=your-tag \

      - run:
          name: Add back-end ip to ansible inventory
          command: |
            export $(grep BACKEND_STACK ~/my_env)
            export $(grep FRONTEND_STACK ~/my_env)
            BACKEND_IP_ADDRESS=$(aws cloudformation describe-stacks --stack-name $BACKEND_STACK --query "Stacks[*].Outputs[?OutputKey=='BackendIP'].OutputValue" --output text)
            INSTANCE_ID=$(aws cloudformation describe-stacks --stack-name $BACKEND_STACK --query "Stacks[*].Outputs[?OutputKey=='InstanceID'].OututValue" --output text)
            BACKEND_IP=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query "Reservations[*].Instances[*].PublicIpAddress" --output text)
            echo BACKEND_IP_ADDRESS $BACKEND_IP_ADDRESS
            echo BACKEND_IP $BACKEND_IP

            echo BACKEND_IP=$BACKEND_IP_ADDRESS >> ~/my_env
            echo $BACKEND_IP_ADDRESS >> .circleci/ansible/inventory.txt

      - persist_to_workspace:
          root: ~/
          paths:
            - project/.circleci/ansible/inventory.txt
            - my_env

      # Destroy the environment if provisioning fails
      - destroy-environment

  configure-infrastructure:
    <<: *ansibleimg
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: [ "73:51:04:63:36:94:d9:04:fa:67:e5:cc:3a:46:df:7f" ]

      # attach workspace
      - attach_workspace:
          at: ~/

      - update_ansible_image
      - run:
          name: Check Directory content
          command: |
            pwd
            ls -al
            ls -al ~/project
            ls -al /
            echo The current user is $(whoami)
      - run:
          name: Configure server
          command: |
            pwd
            cd .circleci/ansible
            sed -i "s/TYPEORM_PASSWORD_STRING/${TYPEORM_PASSWORD}/" roles/configure-server/tasks/main.yml
            sed -i "s/TYPEORM_USERNAME_STRING/${TYPEORM_USERNAME}/" roles/configure-server/tasks/main.yml
            sed -i "s/TYPEORM_HOST_STRING/${TYPEORM_HOST}/" roles/configure-server/tasks/main.yml
            sed -i "s/TYPEORM_DATABASE_STRING/${TYPEORM_DATABASE}/" roles/configure-server/tasks/main.yml
            ansible-playbook -i inventory.txt configure-server.yml
            cat roles/configure-server/tasks/main.yml

      # Destory the environment if provisioning fails
      - destroy-environment

  run-migrations:
    <<: *nodeimg
    steps:
      - checkout
      - attach_workspace:
          at: ~/

      - install_aws_cli
      - run:
          name: Run migrations
          command: |
            pwd
            cd backend
            npm install
            npm run migrations > migrations_dump.txt
            cat migrations_dump.txt

      - run:
          # name: Send migration results to memstash
          name: Send migration results to memstash
          command: |
            pwd
            ls -al
            if grep -q "has been executed successfully." ~/project/backend/migrations_dump.txt
            then
              aws ssm put-parameter --name migration_${CIRCLE_WORKFLOW_ID:0:7} --value 1 --type String
            fi
            cat ~/project/backend/migrations_dump.txt

      # Destory environment if provisioning fails
      - destroy-environment

  # deploy-frontend:
  #   docker:
  #     <<: *awscli
  #   steps:
  #     # Checkout code from git
  #     - run:
  #         name: Install dependencies
  #         command: |
  #           # your code here
  #     - run:
  #         name: Get backend url
  #         command: |
  #           # your code here
  #           export API_URL="http://${BACKEND_IP}:3030"
  #           echo "${API_URL}"
  #     - run:
  #         name: Deploy frontend objects
  #         command: |
  #           # your code here
  #     # Here's where you will add some code to rollback on failure  

workflows:
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      - deploy-infrastructure:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
          filters:
            branches:
              only: [develop]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
      - run-migrations:
          requires: [configure-infrastructure]
      # - deploy-frontend:
      #     requires: [run-migrations]